\section*{Discussion}\label{sec:discussion}
Providing provable guarantees of the superior performance of near term quantum computers relative to any classical device for some particular non-trivial application is an important milestone of the field. We have shown one potential route towards this goal by combining complexity theoretic arguments\cite{bremner_classical_2011, aaronson_computational_2013, boixo_characterizing_2018}, with an application in generative machine learning\cite{gao_efficient_2017, benedetti_generative_2019, liu_differentiable_2018, du_expressive_2018}, and improved training methods of generative models. Specifically we introduced the Ising Born machine, a restricted form of a quantum circuit Born machine. These models utilise the Born rule of quantum mechanics to train a parameterised quantum circuit as a generative machine learning model, in a hybrid manner.
We proved that the model cannot be simulated efficiently by any classical algorithm up to a multiplicative error in the output probabilities, which holds for many circuit families that may be encountered during gradient based training. As such, this type of model is a good candidate for a provable quantum advantage in quantum machine learning using NISQ devices. To formalise this intuition, we defined a notion of quantum learning supremacy to rigorously define what such a advantage would look like, in the context of machine learning.
We adapted novel training methods for generative modelling in two ways. Firstly, by introducing quantum kernels to be evaluated on quantum hardware, and secondly by proposing and adapting new cost functions. In the case of the Sinkhorn divergence, we discussed its sample complexity and used this to define a somewhat optimal cost function through a judicious choice of the regularisation parameter. It is possible to choose this parameter such that the cost is efficiently computable even as the the number of qubits grows. We showed numerically that all these methods have the ability to outperform previous methods in the random dataset we used as a test case. Finally, we demonstrated an application of the model as a heuristic compiler to compile one quantum circuit into another via classical optimisation techniques, which has the advantage of requiring minimal quantum overhead. These techniques could potentially be adapted into methods to benchmark and verify near term quantum devices.
The major question that this work raises is whether or not a provable notion of quantum learning could be achievable for a particular dataset, thereby solidifying a use case for quantum computers in the near term with provable advantage. The best prospect for this is the quantum supremacy distributions we know of (for example $\IQP$), but they are not efficiently testable\cite{hangleiter_sample_2018}. Due to this, they are also likely to not be efficiently learnable either, given the close relationship between distribution testing and learning\cite{goldreich_property_1998}. However, this assumes we have access only to classical samples from the distribution, and the possibility of gaining an advantage using \textit{quantum} samples\cite{schuld_supervised_2018, arunachalam_survey_2017} is unexplored in the context of distribution learning. 