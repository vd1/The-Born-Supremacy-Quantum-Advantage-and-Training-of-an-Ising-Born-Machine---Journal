% !TEX root = ../main.tex

\begin{abstract}
    The search for an application of near-term quantum devices is widespread. Quantum machine learning is touted as a potential utilisation of such devices, particularly those out of the reach of the simulation capabilities of classical computers. In this work, we study such an application in generative modelling, focusing on a class of quantum circuits known as Born machines. Specifically, we define a subset of this class based on Ising Hamiltonians, and show that the circuits encountered during gradient-based training cannot be efficiently sampled from classically, up to multiplicative error in the worst case. Our gradient-based training methods use cost functions known as the Sinkhorn divergence and the Stein discrepancy 
which where not previously used in a quantum context, and also introduce quantum kernels to generative modelling. We show that they outperform the previous standard method, which used maximum mean discrepancy ($\MMD$) as a cost function, and this with minimal overhead. Finally, we discuss the ability of the model to learn hard distributions and provide the first formal definitions for `quantum learning supremacy', with a novel example of using generative modelling for quantum circuit compilation.
    
    
    
    % In this work, we propose a generative Quantum Machine Learning Model, called the Ising Born Machine ($\IBM$), which we show cannot, in the worst case, and up to suitable notions of error, be simulated efficiently by a classical device. We also show this holds for all the circuit families encountered during training. In particular, we explore quantum circuit learning using non-universal circuits derived from Ising Model Hamiltonians, which are implementable on near term quantum devices. 
    
    % We propose two novel training methods for the $\IBM$ by utilising the \textit{Stein Discrepancy} and the \textit{Sinkhorn Divergence} cost functions. We show numerically, both using a simulator within Rigetti's Forest platform and on the Aspen-1 16Q chip, that the cost functions we suggest outperform the more commonly used Maximum Mean Discrepancy ($\MMD$) in particular. We also propose an improvement to the $\MMD$ by performing a novel utilisation of a \emph{quantum kernels} which we also demonstrate provides improvements over its classical counterpart. We discuss the potential of these methods to learn `\textit{hard}' quantum distributions, a feat which would demonstrate the advantage of quantum over classical computers, and provide the first formal definitions for what we call `\emph{Quantum Learning Supremacy}'. We also propose a novel view on the area of quantum circuit compilation by using the $\IBM$ to `mimic' target quantum circuits using classical output data only.
\end{abstract}

